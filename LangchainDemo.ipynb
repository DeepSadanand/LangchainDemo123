{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup environment variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "env_var = load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "HUGGINGFACEHUB_API = os.getenv(\"HUGGINGFACEHUB_API\")\n",
    "# print(OPENAI_API_KEY, HUGGINGFACE_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_11368\\2597424649.py:2: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAI``.\n",
      "  llm = OpenAI()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OpenAI(client=<openai.resources.completions.Completions object at 0x00000182257CA450>, async_client=<openai.resources.completions.AsyncCompletions object at 0x000001822589ABD0>, model_kwargs={}, openai_api_key='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', openai_proxy='', logit_bias={})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "llm = OpenAI()\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gpt-3.5-turbo-instruct'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.model_name # by default model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature = 0.6) # temp = how creative we want our model 0 - model safe not creative 1- may generate wrong putpt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Tell me something about TCS, India\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_11368\\1119240448.py:1: LangChainDeprecationWarning: The method `BaseLLM.predict` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  print(llm.predict(prompt))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Tata Consultancy Services (TCS) is a multinational information technology (IT) services, consulting, and business solutions company headquartered in Mumbai, India. It is the largest IT services company in India and one of the largest in the world, with a market capitalization of over $100 billion.\n",
      "\n",
      "TCS was founded in 1968 by Tata Sons as a division of Tata Sons Limited. It was initially set up to provide IT services to other Tata group companies but later expanded its services to other clients. Today, TCS has a presence in over 46 countries and serves clients in various industries such as banking, finance, insurance, healthcare, telecommunications, and more.\n",
      "\n",
      "TCS is known for its innovative approach and has been at the forefront of the digital transformation in India. It has a strong focus on research and development, with over 200,000 employees dedicated to innovation. TCS has also been recognized for its commitment to sustainability and social responsibility, with initiatives such as the TCS Foundation, which works towards education, health, and environment-related causes.\n",
      "\n",
      "In addition to its IT services, TCS also offers business consulting, digital solutions, and engineering services. It has a strong track record of delivering complex projects and has been recognized as a leader in the IT industry\n"
     ]
    }
   ],
   "source": [
    "print(llm.predict(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nTata Consultancy Services (TCS) is an Indian multinational information technology (IT) service, consulting, and business solutions company headquartered in Mumbai, Maharashtra. It is the largest IT service provider in India and one of the top IT companies in the world. Founded in 1968, TCS is a subsidiary of the Tata Group, one of India's largest and oldest conglomerates.\\n\\nTCS offers a wide range of services including software development, infrastructure management, consulting, and engineering services. It serves clients in various industries such as banking, finance, insurance, healthcare, retail, and manufacturing. TCS has a global presence with operations in over 46 countries and has delivery centers in several countries including India, China, the United States, and the United Kingdom.\\n\\nTCS is known for its strong focus on innovation and technology, with a significant investment in research and development. It has received numerous awards and recognitions for its work, including being ranked as one of the World's Most Admired Companies by Fortune magazine and being named as the top employer in the Indian IT industry.\\n\\nIn addition to its business operations, TCS is also committed to social responsibility and sustainability. The company has various initiatives in place to support education, health, and the environment, and has\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_11368\\1917098224.py:2: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  print(llm(prompt2))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Pritika\n",
      "2. Prisha\n",
      "3. Prithvi\n",
      "4. Priyanka\n",
      "5. Pritha\n",
      "6. Pritam\n",
      "7. Priyam\n",
      "8. Prithvi Raj\n",
      "9. Priyansh\n",
      "10. Prishaan\n"
     ]
    }
   ],
   "source": [
    "prompt2 = \"Give me 10 baby name start with Pri in Hindu\"\n",
    "print(llm(prompt2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_11368\\3177716484.py:2: LangChainDeprecationWarning: The class `HuggingFaceHub` was deprecated in LangChain 0.0.21 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEndpoint``.\n",
      "  hugging_llm = HuggingFaceHub(repo_id = \"google/gemma-2-2b-it\", model_kwargs = {\"temperature\": 0.6} ,huggingfacehub_api_token = HUGGINGFACEHUB_API)\n",
      "c:\\Users\\DELL\\anaconda3\\envs\\lang_test\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain import HuggingFaceHub\n",
    "hugging_llm = HuggingFaceHub(repo_id = \"google/gemma-2-2b-it\", model_kwargs = {\"temperature\": 0.6} ,huggingfacehub_api_token = HUGGINGFACEHUB_API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_7500\\1568527575.py:1: LangChainDeprecationWarning: The method `BaseLLM.predict` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  print(hugging_llm.predict(\"I want to open a resturant for Indian food. Suggest a fancy name for this\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I want to open a resturant for Indian food. Suggest a fancy name for this restaurant?\n",
      "\n",
      "Here are some ideas based on different aspects:\n",
      "\n",
      "**Spice & Flavor:**\n",
      "\n",
      "* Saffron & Spice\n",
      "* Masala Magic\n",
      "* The Curry Collective\n",
      "* Tandoori Dreams\n",
      "* Chutney & Co.\n",
      "\n",
      "**Location & History:**\n",
      "\n",
      "* The Bombay Bungalow\n",
      "* The Spice Merchant\n",
      "* The Delhi Den\n",
      "* The Agra Express\n",
      "* The Madras Mansion\n",
      "\n",
      "**Theme & Ambience:**\n",
      "\n",
      "* The Saffron Table\n",
      "* The Taj Mahal Grill\n",
      "* The Tando\n"
     ]
    }
   ],
   "source": [
    "print(hugging_llm.predict(\"I want to open a resturant for Indian food. Suggest a fancy name for this\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I want to open a restaurant for Sri Lankan food, suggest 5 names for this\n"
     ]
    }
   ],
   "source": [
    "\n",
    "llm3 = OpenAI(temperature = 0.7)\n",
    "prompt_template = PromptTemplate(input_variables= ['cusine'], \n",
    "               template = \"I want to open a restaurant for {cusine} food, suggest 5 names for this\"\n",
    "               )\n",
    "\n",
    "p = prompt_template.format(cusine = \"Sri Lankan\")\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I want to open a restaurant for German food, suggest 5 names for this'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = prompt_template.format(cusine = \"German\")\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have a company please describe Apple in 15 words\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "pt = PromptTemplate(input_variables = [\"product\"],\n",
    "                    template = \"I have a company please describe {product} in 15 words\"\n",
    "                    )\n",
    "# print(pt.fill(input_variables={\"product\": \"apple\"}))\n",
    "prompt1 = pt.format(product = 'Apple')\n",
    "print(prompt1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.llms import OpenAI\n",
    "llm = OpenAI(temperature = 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is a good name for a company that makes Colorful socks'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"What is a good name for a company that makes {product}\")\n",
    "prompt.format(product= 'Colorful socks')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_11368\\2703641394.py:2: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain = LLMChain(llm = llm, prompt = prompt)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_11368\\2703641394.py:3: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = chain.run(\"colorful socks\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Rainbow Socks Co. \n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "chain = LLMChain(llm = llm, prompt = prompt)\n",
    "response = chain.run(\"colorful socks\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Sequential Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI()\n",
    "\n",
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables = [\"cusine\"],\n",
    "    template = \"I want to open a restaurant for {cusine} food. Suggest a best restaurant name\"\n",
    ")\n",
    "\n",
    "name_chain = LLMChain(llm = llm, prompt = prompt_template_name)\n",
    "\n",
    "prompt_template_item = PromptTemplate(\n",
    "    input_variables = ['restaurant_name'],\n",
    "    template = \" Suggest some menu items for {restaurat_name}\"\n",
    "    )\n",
    "\n",
    "food_item_chain = LLMChain(llm = llm, prompt = prompt_template_item)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":\n",
      "\n",
      "1. Spicy Chicken Curry with Basmati Rice\n",
      "2. Vegetable Samosas\n",
      "3. Lamb Vindaloo\n",
      "4. Tandoori Chicken Skewers\n",
      "5. Aloo Gobi (Potato and Cauliflower Curry)\n",
      "6. Garlic Naan Bread\n",
      "7. Palak Paneer (Spinach and Cheese Curry)\n",
      "8. Chana Masala (Chickpea Curry)\n",
      "9. Mango Lassi (Mango Yogurt Drink)\n",
      "10. Chicken Tikka Masala\n",
      "11. Vegetable Biryani\n",
      "12. Papadum (Crispy Lentil Crackers)\n",
      "13. Lamb Rogan Josh\n",
      "14. Baingan Bharta (Roasted Eggplant Curry)\n",
      "15. Gulab Jamun (Fried Milk Dumplings in Syrup)\n"
     ]
    }
   ],
   "source": [
    "import langchain\n",
    "# import langchain.chains import SimpleSequentialChain\n",
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "chain = SimpleSequentialChain(chains = [name_chain,food_item_chain])\n",
    "content = chain.run('Indian')\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sequential Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature = 0.7)\n",
    "\n",
    "prompt_template_name = PromptTemplate(input_variables = [\"cusine\"],\n",
    "               template = \"I want to open a restaurant for {cusine} food , suggest me a good name for it\"\n",
    "               )\n",
    "\n",
    "name_chain = LLMChain(llm = llm, prompt = prompt_template_name, output_key = \"restaurant_name\")\n",
    "\n",
    "prompt_template_name = PromptTemplate(input_variables = [\"restaurant_name\"],\n",
    "                                      template = \"Suggest Some menu for {restaurant_name}\"\n",
    "                                      )\n",
    "\n",
    "food_item_chain = LLMChain(llm = llm, prompt = prompt_template_name, output_key = \"menu_items\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chain Example\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_11368\\2617142913.py:9: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  print (chain({\"cusine\":'Italian'}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cusine': 'Italian', 'restaurant_name': '\\n\\n1. \"Bella Cucina\" (Beautiful Kitchen)\\n2. \"La Dolce Vita\" (The Sweet Life)\\n3. \"Ciao Bella\" (Hello Beautiful)\\n4. \"Mangia Bene\" (Eat Well)\\n5. \"Festa Italiana\" (Italian Feast)\\n6. \"Gusto Italiano\" (Italian Flavors)\\n7. \"Bella Tavola\" (Beautiful Table)\\n8. \"La Famiglia\" (The Family)\\n9. \"Amore di Cucina\" (Love of Cooking)\\n10. \"Trattoria da Vinci\" (Da Vinci\\'s Trattoria)', 'menu_items': ' \\n\\nMenu:\\n\\n1. Appetizers:\\n- Bruschetta with fresh tomatoes, basil, and mozzarella\\n- Arancini (fried risotto balls) with marinara sauce\\n- Prosciutto and melon skewers\\n- Fried calamari with lemon aioli\\n- Caprese salad with balsamic glaze\\n\\n2. Salads:\\n- Caesar salad with homemade dressing and croutons\\n- Insalata mista (mixed greens) with balsamic vinaigrette\\n- Panzanella (bread and tomato) salad \\n- Beet and goat cheese salad with honey vinaigrette \\n\\n3. Pasta:\\n- Spaghetti carbonara (pancetta, egg, and parmesan)\\n- Penne alla vodka (tomato cream sauce with vodka)\\n- Gnocchi with pesto sauce and pine nuts\\n- Lasagna Bolognese (meat and tomato sauce with bechamel)\\n\\n4. Main Courses:\\n- Chicken Parmigiana with marinara sauce and melted mozzarella\\n- Veal Marsala (marsala wine and mushroom sauce)\\n- Eggplant Parmigiana with marinara sauce and melted mozzarella\\n- Shrimp Scampi with garlic butter sauce and linguine\\n\\n5. Pizzas:\\n'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "\n",
    "chain = SequentialChain (\n",
    "    chains = [name_chain,food_item_chain],\n",
    "    input_variables = ['cusine'],\n",
    "    output_variables= ['restaurant_name',\"menu_items\"]\n",
    ")\n",
    "print(\"Chain Example\")\n",
    "print (chain({\"cusine\":'Italian'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agents and Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'GoogleSearch' from 'serpapi' (c:\\Users\\DELL\\anaconda3\\envs\\lang_test\\Lib\\site-packages\\serpapi\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magents\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_tools,AgentType, initialize_agent\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mserpapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GoogleSearch\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[0;32m      4\u001b[0m llm \u001b[38;5;241m=\u001b[39m OpenAI(temperature \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.6\u001b[39m)\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'GoogleSearch' from 'serpapi' (c:\\Users\\DELL\\anaconda3\\envs\\lang_test\\Lib\\site-packages\\serpapi\\__init__.py)"
     ]
    }
   ],
   "source": [
    "# from langchain.agents import load_tools,AgentType, initialize_agent\n",
    "# from serpapi import GoogleSearch\n",
    "# from langchain.llms import OpenAI\n",
    "# llm = OpenAI(temperature = 0.6)\n",
    "\n",
    "\n",
    "\n",
    "# load_tools(['serpapi','llm-math'],llm = llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "SERPAPI_API_KEY = os.getenv(\"SERPAPI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lang_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
